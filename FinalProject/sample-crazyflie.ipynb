{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae02839",
   "metadata": {},
   "source": [
    "# Sample code for performing obstacle avoidance #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ee24e",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc056ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/autonomousSequence.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CrazyFlie imports:\n",
    "\n",
    "import cflib.crtp\n",
    "from cflib.crazyflie import Crazyflie\n",
    "from cflib.crazyflie.log import LogConfig\n",
    "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
    "from cflib.crazyflie.syncLogger import SyncLogger\n",
    "from cflib.positioning.position_hl_commander import PositionHlCommander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce9da5",
   "metadata": {},
   "source": [
    "Set your group number and camera number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb41bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_number = 13\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363ab6b",
   "metadata": {},
   "source": [
    "## Tune the red filtering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758561cb",
   "metadata": {},
   "source": [
    "You can use the following cell to test and visualize the red filtering. This cell *not* make the drone fly. It will connect to the CrazyFlie camera and perform red filtering on the live video feed. You should use this cell to tune the HSV intervals, and then copy/paste your tuned intervals into the __check_contours__ function below. When tuning the intervals, keep in mind that the lighting in the environment can matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2084245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_bounding_boxes()\n",
    "OBSTACLE_CONTOUR_THRESHOLD = 750\n",
    "\n",
    "def get_bounding_boxes(frame):\n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (145, 35, 75)\n",
    "    ub1 = (180, 255, 255)\n",
    "    lb2 = (0, 75, 75)\n",
    "    ub2 = (20, 255, 255)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    boundRect = []\n",
    "    for i, c in enumerate(contours):\n",
    "        if cv2.contourArea(contours[i]) > OBSTACLE_CONTOUR_THRESHOLD:\n",
    "            boundRect.append(cv2.boundingRect(c))\n",
    "    print(f\"Bounding Rectangles Found: {len(boundRect)}\")\n",
    "    return boundRect\n",
    "\n",
    "def get_book_box(frame):\n",
    "    lb1 = (100, 170, 220)#(5, 100, 100)\n",
    "    ub1 = (120, 210, 235)#(30, 200, 200)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    mask = cv2.inRange(hsv1, lb1, ub1)\n",
    "    \n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Find the largest contour (should be the book)\n",
    "    largest_area = 0\n",
    "    largest_ind = -1\n",
    "    \n",
    "    for i, c in enumerate(contours):\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_ind = i\n",
    "    \n",
    "    return cv2.boundingRect(c) if largest_ind != -1 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107adf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rng\n",
    "import numpy as np\n",
    "import argparse\n",
    "cap = cv2.VideoCapture(camera)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    boundRect = get_bounding_boxes(frame)\n",
    "    \n",
    "    for i in range(len(boundRect)):\n",
    "        color = (0, 255, 0)\n",
    "        cv2.rectangle(frame, (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "          (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
    "    \n",
    "    boundRect = get_book_box(frame)\n",
    "    if boundRect is not None:\n",
    "        color = (255,0,0)\n",
    "        cv2.rectangle(frame, (int(boundRect[0]), int(boundRect[1])), \\\n",
    "          (int(boundRect[0]+boundRect[2]), int(boundRect[1]+boundRect[3])), color, 2)\n",
    "    \n",
    "    # shows all the bounding boxes for obstacles and the book\n",
    "    cv2.imshow(\"Contours\", frame)\n",
    "    \n",
    "    # Compute\n",
    "    #cv2.imshow('mask', mask)    \n",
    "\n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block allows us to take screenshots and save the image\n",
    "cap = cv2.VideoCapture(camera)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Contours\", frame)\n",
    "    key_pressed = cv2.waitKey(1)\n",
    "    if key_pressed & 0xFF == ord('p'):\n",
    "        cv2.imwrite(\"book.png\", frame)\n",
    "    \n",
    "    # Hit q to quit.\n",
    "    if key_pressed & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if code using the camera errors, then we call this block\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if some opencv windows linger, we can call this to destroy them\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca37f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for book bounding box\n",
    "frame = cv2.imread('book.png')\n",
    "boundRect, mask = get_book_box(frame)\n",
    "print(boundRect)\n",
    "if boundRect is not None:\n",
    "    color = (255,0,0)\n",
    "    cv2.rectangle(frame, (int(boundRect[0]), int(boundRect[1])), \\\n",
    "      (int(boundRect[0]+boundRect[2]), int(boundRect[1]+boundRect[3])), color, 2)\n",
    "    \n",
    "while True:\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5faef",
   "metadata": {},
   "source": [
    "## Helper functions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dde9dd",
   "metadata": {},
   "source": [
    "The following cell contains some sample functions which will be useful.\n",
    "\n",
    "In particular, __check_contours__ and __findGreatesContour__ will perform red filtering on the live camera feed and identify the obstacles. The red filtering is controlled by setting HSV intervals in the __check_contours__ function. Note that the intervals will require tuning and may vary on different drones/cameras.\n",
    "\n",
    "The __adjust_position__ function can also be modified for performing obstacle avoidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45694074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current crazyflie position:\n",
    "def position_estimate(scf):\n",
    "    log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
    "    log_config.add_variable('kalman.varPX', 'float')\n",
    "    log_config.add_variable('kalman.varPY', 'float')\n",
    "    log_config.add_variable('kalman.varPZ', 'float')\n",
    "\n",
    "    with SyncLogger(scf, log_config) as logger:\n",
    "        for log_entry in logger:\n",
    "            data = log_entry[1]\n",
    "            x = data['kalman.varPX']\n",
    "            y = data['kalman.varPY']\n",
    "            z = data['kalman.varPZ']\n",
    "            \n",
    "    print(x, y, z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "# Set the built-in PID controller:\n",
    "def set_PID_controller(cf):\n",
    "    # Set the PID Controller:\n",
    "    print('Initializing PID Controller')\n",
    "    cf.param.set_value('stabilizer.controller', '1')\n",
    "    cf.param.set_value('kalman.resetEstimation', '1')\n",
    "    time.sleep(0.1)\n",
    "    cf.param.set_value('kalman.resetEstimation', '0')\n",
    "    time.sleep(2)\n",
    "    return\n",
    "\n",
    "\n",
    "# Ascend and hover at 1m:\n",
    "def ascend_and_hover(cf):\n",
    "    # Ascend:\n",
    "    # NOTE: was changed from starter code - made ascent a little smoother\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, y / 20) # vx (m/s), vy (m/s), yaw_rate (deg/s), z_height (m)\n",
    "        time.sleep(0.1)\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5) # vx (m/s), vy (m/s), yaw_rate (deg/s), z_height (m)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "\n",
    "\n",
    "# Sort through contours in the image\n",
    "def findGreatesContour(contours):\n",
    "    largest_area = 0\n",
    "    largest_contour_index = -1\n",
    "    i = 0\n",
    "    total_contours = len(contours)\n",
    "\n",
    "    while i < total_contours:\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_contour_index = i\n",
    "        i += 1\n",
    "\n",
    "    #print(largest_area)\n",
    "\n",
    "    return largest_area, largest_contour_index\n",
    "\n",
    "\n",
    "# Find contours in the image\n",
    "def check_contours(frame):\n",
    "\n",
    "    print('Checking image:')\n",
    "\n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (145, 35, 75)\n",
    "    ub1 = (180, 255, 255)\n",
    "    lb2 = (0, 75, 75)\n",
    "    ub2 = (20, 255, 255)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_area, largest_contour_index = findGreatesContour(contours)\n",
    "\n",
    "    print(largest_area)\n",
    "\n",
    "    if largest_area > 100:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Follow the setpoint sequence trajectory:\n",
    "def adjust_position(cf, current_y):\n",
    "\n",
    "    print('Adjusting position')\n",
    "\n",
    "    steps_per_meter = int(10)\n",
    "    # Set the number here (the iterations of the for-loop) to the number of side steps.\n",
    "    # You may choose to tune the number and size of the steps.\n",
    "    for i in range(3): \n",
    "        current_y = current_y - 1.0/float(steps_per_meter)\n",
    "        position = [0, current_y, 0.5, 0.0]\n",
    "\n",
    "        print('Setting position {}'.format(position))\n",
    "        for i in range(10):\n",
    "            cf.commander.send_position_setpoint(position[0],\n",
    "                                                position[1],\n",
    "                                                position[2],\n",
    "                                                position[3]) # x_pos (m), y_pos (m), z_pos (m), yaw (deg)\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    cf.commander.send_stop_setpoint() # From documentation \"Send STOP setpoing, stopping the motors and (potentially) falling.\"\n",
    "    # Make sure that the last packet leaves before the link is closed.\n",
    "    # The message queue is not flushed before closing.\n",
    "    time.sleep(0.1)\n",
    "    return current_y\n",
    "\n",
    "\n",
    "# Hover, descend, and stop all motion:\n",
    "def hover_and_descend(cf):\n",
    "    print('Descending:')\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(30):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5) # vx (m/s), vy (m/s), yaw_rate (deg/s), z_height (m)\n",
    "        time.sleep(0.1)\n",
    "    # Descend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, (10 - y) / 25) # vx (m/s), vy (m/s), yaw_rate (deg/s), z_height (m)\n",
    "        time.sleep(0.1)\n",
    "    # Stop all motion:\n",
    "    for i in range(10):\n",
    "        cf.commander.send_stop_setpoint() # From documentation \"Send STOP setpoing, stopping the motors and (potentially) falling.\"\n",
    "        time.sleep(0.1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fbec4",
   "metadata": {},
   "source": [
    "## Test obstacle avoidance on the CrazyFlie ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd18e2",
   "metadata": {},
   "source": [
    "The following cell *will* fly the drone. Place the CrazyFlie in front of an obstacle in the netted area for testing. This cell will perform object detection and avoidance using the red filtering defined in the helper functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca756a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def hover(cf, iterations=1):\n",
    "    for _ in range(iterations):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    print(\"Hover\")\n",
    "    \n",
    "DEBUG = False\n",
    "def tprint(s):\n",
    "    if DEBUG:\n",
    "        print(s)\n",
    "# TODO come up with better way to end a trial early (currently depending on using opencv window)\n",
    "# TODO figure out camera failures\n",
    "\n",
    "# strategy list:\n",
    "# 0: just hover (debug)\n",
    "# 1: move_between_boxes\n",
    "CURR_STRATEGY = 1\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "fps = 20\n",
    "image_size = (640, 480)\n",
    "file_name = 'video_crazyflie.avi'\n",
    "\n",
    "video = cv2.VideoWriter(file_name,cv2.VideoWriter_fourcc('M','J','P','G'), fps, image_size)\n",
    "\n",
    "r = FrameRejection(3)\n",
    "\n",
    "# Check that CrazyFlie devices are available:\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascent to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "        current_y = 0.0\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        prev_time = t\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        # CHANGED FROM STARTER CODE:\n",
    "        # Currently, the drone hovers until we press q on the opencv window\n",
    "        while(cap.isOpened()):\n",
    "            \n",
    "            bruh = time.time()\n",
    "            ret, frame = cap.read()\n",
    "            tprint(f\"Camera read: {time.time() - bruh}\")\n",
    "            bruh = time.time()\n",
    "            \n",
    "            elapsed = time.time() - t\n",
    "            if(elapsed > 5.0):\n",
    "                if ret:\n",
    "                    cv2.imshow('frame',frame)\n",
    "\n",
    "                    if(ascended_bool==0):\n",
    "                        set_PID_controller(cf)\n",
    "                        ascend_and_hover(cf)\n",
    "                        ascended_bool = 1\n",
    "                        curr_x, curr_y = 0, 0 # ADDED\n",
    "                    else:\n",
    "                        frame = r.should_reject_frame(frame)\n",
    "                        if frame is not None:\n",
    "                            boundRect = get_bounding_boxes(frame)\n",
    "                            tprint(f\"Obstacle detection: {time.time() - bruh}\")\n",
    "                            bruh = time.time()\n",
    "\n",
    "                            for i in range(len(boundRect)):\n",
    "                                color = (0, 255, 0)\n",
    "                                cv2.rectangle(frame, (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "                                  (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
    "\n",
    "                            bookRect = get_book_box(frame)\n",
    "                            if bookRect is not None:\n",
    "                                color = (0,0,255)\n",
    "                                cv2.rectangle(frame, (int(bookRect[0]), int(bookRect[1])), \\\n",
    "                                  (int(bookRect[0]+bookRect[2]), int(bookRect[1]+bookRect[3])), color, 2)\n",
    "\n",
    "                            video.write(frame)\n",
    "                            tprint(f\"Video write/box drawing: {time.time() - bruh}\")\n",
    "                            bruh = time.time()\n",
    "\n",
    "                            # TEST - if no obstacles, either land or center on book\n",
    "                            if not boundRect:\n",
    "                                # if nothing is found, hover and pray the camera finds something later\n",
    "                                if not bookRect:\n",
    "                                    hover(cf)\n",
    "                                    tprint(f\"Hover when nothing found: {time.time() - bruh}\")\n",
    "                                    bruh = time.time()\n",
    "                                else:\n",
    "                                    curr_x, curr_y, goal_reached = move_towards_book(cf, curr_x, curr_y, bookRect)\n",
    "                                    tprint(f\"Moving towards book: {time.time() - bruh}\")\n",
    "                                    bruh = time.time()\n",
    "                                    if goal_reached:\n",
    "                                        print(\"goal reached\")\n",
    "                                        break\n",
    "\n",
    "                            if CURR_STRATEGY == 0:\n",
    "                                hover(cf)\n",
    "                                tprint(f\"Hover debug: {time.time() - bruh}\")\n",
    "                                bruh = time.time()\n",
    "                            elif CURR_STRATEGY == 1:\n",
    "                                if boundRect:\n",
    "                                    curr_x, curr_y = move_between_boxes(cf, curr_x, curr_y, boundRect, bookRect)\n",
    "                                    print(curr_x, curr_y)\n",
    "                                else:\n",
    "                                    hover(cf)\n",
    "\n",
    "                            cv2.imshow(\"Contours\", frame)\n",
    "                            tprint(f\"Show frame: {time.time() - bruh}\")\n",
    "                        else:\n",
    "                            hover(cf)\n",
    "                        bruh = time.time()\n",
    "                        # NOTE: DO NOT SPAM q - inputs are stored to a buffer and will cause subsequent trials to end early\n",
    "                        if (cv2.waitKey(10) & 0xFF) == ord('q'):\n",
    "                            print(\"hello\")\n",
    "                            break\n",
    "                    \n",
    "                    tprint(time.time() - prev_time)\n",
    "                    prev_time = time.time()\n",
    "        \n",
    "        cap.release()\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# TUNABLE PARAMETERS\n",
    "# is_forward_safe()\n",
    "LB = 210 # lower bound for x coordinate of obstacle avoidance\n",
    "UB = 430 # upper bound for x coordinate of obstace avoidance\n",
    "WIDTH_THRESHOLD = 70 # width of obstacle in camera view\n",
    "\n",
    "# move_towards_book()\n",
    "BOOK_SIZE = 10000 # area of book before we stop moving the drone\n",
    "BOOK_OFFSET = 0.1 # threshold of how far the center of the book should be from the center of the FOV before stopping\n",
    "BOOK_STEP_SIZE = 0.5 # lateral movement scaling when centering on book\n",
    "\n",
    "# move_between_boxes()\n",
    "CENTRAL_GAP_WEIGHT = 1.4\n",
    "FORWARD_STEP = 0.15 # distance drone moves forward\n",
    "SIDE_STEP = 0.1 # distance drone moves sideways\n",
    "\n",
    "# FrameRejection\n",
    "BLUR_WINDOW = (11,11)\n",
    "HISTOGRAM_BIN_SIZES = [8,8,8]\n",
    "SIMILARITY_THRESHOLD = 0.75\n",
    "FRAME_STRAT = 1\n",
    "# 0 - Rolling window of histograms\n",
    "# 1 - average frame\n",
    "\n",
    "# transforms pixel x coordinates to normalized coordinates ([0, image width] -> [-1, 1])\n",
    "def get_normalized_x(x):\n",
    "    image_half_width = 320 # TODO verify actual image width\n",
    "    return (x - image_half_width) / (image_half_width << 1)\n",
    "\n",
    "# determines if the drone can move forward safely based on whether or not an obstacle is in some band in front of it\n",
    "def is_forward_safe(obs):\n",
    "    for o in obs:\n",
    "        x, _, w, _ = o\n",
    "        if LB < x < UB: # TODO see if we need to check if any part of obstacle is in band\n",
    "            if min(x + w, UB) - max(x, LB)  > WIDTH_THRESHOLD: # TEST - determine if this threshold idea works\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# returns updated x and y, also whether or not drone is centered on book\n",
    "def move_towards_book(cf, curr_x, curr_y, book):\n",
    "    dest = get_normalized_x(book[0] + book[2] / 2)\n",
    "    \n",
    "    # TEST - choosing distance threshold\n",
    "    if book[2] * book[3] > BOOK_SIZE and abs(dest) < BOOK_OFFSET:\n",
    "        return curr_x, curr_y, True\n",
    "    \n",
    "    new_y = curr_y - dest * BOOK_STEP_SIZE\n",
    "    cf.commander.send_position_setpoint(curr_x, new_y, 0.5, 0.0)\n",
    "    return curr_x, new_y, False\n",
    "\n",
    "# TODO handle no valid gap case\n",
    "# bounding boxes are (I think) in the form of (top left x, top left y, width, height)\n",
    "# returns updated x and y coordinates\n",
    "def move_between_boxes(cf, curr_x, curr_y, obstacles, book):\n",
    "    # choose destination here\n",
    "    if book is None:\n",
    "        # TEST - choose the largest gap if book is not visible\n",
    "        sorted_obs = sorted(obstacles, key=lambda x: x[0])\n",
    "        \n",
    "        if curr_y < 0.5:\n",
    "            champ_gap = sorted_obs[0][0]\n",
    "            dest = sorted_obs[0][0] >> 1\n",
    "        else:\n",
    "            next_x = 640 if len(sorted_obs) < 2 else sorted_obs[1][0]\n",
    "            obs_x, _ , width, _ = sorted_obs[0]\n",
    "            champ_gap = next_x - obs_x - width\n",
    "            dest = (obs_x + width + next_x) >> 1\n",
    "            \n",
    "        for i in range(len(obstacles) - 1):\n",
    "            obs_x, _ , width, _ = sorted_obs[i]\n",
    "            next_x = sorted_obs[i + 1][0]\n",
    "            gap = (next_x - obs_x - width) * CENTRAL_GAP_WEIGHT # TEST - weight the central gaps more\n",
    "            if gap > champ_gap:\n",
    "                champ_gap = gap\n",
    "                dest = (obs_x + width + next_x) >> 1\n",
    "        \n",
    "        if curr_y > -0.5:\n",
    "            # handles right most gap\n",
    "            obs_x, _ , width, _ = sorted_obs[-1]\n",
    "            next_x = 640 # TODO figure out image width\n",
    "            gap = next_x - obs_x - width\n",
    "            if gap > champ_gap:\n",
    "                champ_gap = gap\n",
    "                dest = (obs_x + width + next_x) >> 1\n",
    "        \n",
    "    else:\n",
    "        # TEST - choose the book center as the destination\n",
    "        dest = book[0] + (book[2] >> 1)\n",
    "    \n",
    "    normalized_dest = get_normalized_x(dest)\n",
    "    \n",
    "    new_x = curr_x + is_forward_safe(obstacles) * FORWARD_STEP\n",
    "    \n",
    "    new_y = curr_y - normalized_dest * SIDE_STEP # TEST - see how much drone can move laterally\n",
    "    \n",
    "    cf.commander.send_position_setpoint(new_x, new_y, 0.5, 0.0)\n",
    "    return new_x, new_y\n",
    "\n",
    "class FrameRejection:\n",
    "    def __init__(self, buffer_size=0):\n",
    "        self.first_hist = None\n",
    "        self.good_frames = deque()\n",
    "        self.buffer_size = buffer_size\n",
    "        self.frame_count = 0\n",
    "    \n",
    "    def insert_frame(self, frame):\n",
    "        if self.buffer_size > 0 and len(self.good_frames) == self.buffer_size:\n",
    "            self.good_frames.popleft()\n",
    "        self.good_frames.append(frame)\n",
    "        \n",
    "    def should_reject_frame(self, frame):\n",
    "        frame = cv2.medianBlur(frame, 7)#cv2.GaussianBlur(frame, BLUR_WINDOW, 0) # Smooth the image from smaller noise\n",
    "        \n",
    "        if FRAME_STRAT == 0:\n",
    "            # calculate the histogram for the current frame to create a (bin size)^3 size feature vector\n",
    "            curr_hist = cv2.calcHist([frame], [0,1,2], None, HISTOGRAM_BIN_SIZES, [0,256,0,256,0,256])\n",
    "            curr_hist = cv2.normalize(curr_hist, curr_hist).flatten()\n",
    "\n",
    "            # TEST - current rejection strategy is to see if the frame is similar to a rolling window\n",
    "            if self.first_hist is None:\n",
    "                self.frame_count += 1\n",
    "                if self.frame_count == 1:\n",
    "                    return frame\n",
    "                self.first_hist = curr_hist\n",
    "                self.insert_frame(frame)\n",
    "                return frame\n",
    "\n",
    "            similarity = cv2.compareHist(curr_hist, self.first_hist, cv2.HISTCMP_CORREL)\n",
    "            #print(f\"Similarity: {similarity}\")\n",
    "            if similarity > SIMILARITY_THRESHOLD:\n",
    "                self.insert_frame(frame)\n",
    "                updated_hist = cv2.calcHist(self.good_frames, [0,1,2], None, HISTOGRAM_BIN_SIZES, [0,256,0,256,0,256])\n",
    "                self.first_hist = cv2.normalize(updated_hist, updated_hist).flatten()\n",
    "            \n",
    "            return frame if similarity > SIMILARITY_THRESHOLD else None\n",
    "        elif FRAME_STRAT == 1:\n",
    "            self.insert_frame(frame)\n",
    "            avg_frame = self.good_frames[0]\n",
    "            for i in range(1, len(self.good_frames)):\n",
    "                alpha = 1.0/(i + 1)\n",
    "                beta = 1.0 - alpha\n",
    "                avg_frame = cv2.addWeighted(self.good_frames[i], alpha, avg_frame, beta, 0.0)\n",
    "            \n",
    "            return avg_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture('wtf_mae345.avi')\n",
    "prev_frame = None\n",
    "similarity = 1\n",
    "rejections = 0\n",
    "frames = 0\n",
    "\n",
    "r = FrameRejection(10)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    curr = time.time()\n",
    "    frame = r.should_reject_frame(frame)\n",
    "    print(f\"Calc time: {time.time() - curr}\")\n",
    "    \n",
    "    # rejects frame if similarity is not high enough\n",
    "    if frame is None:\n",
    "        frame = prev_frame\n",
    "        rejections += 1\n",
    "    \n",
    "    prev_frame = frame\n",
    "    \n",
    "    # Code to increase contrast of the image\n",
    "    # frame = cv2.convertScaleAbs(frame,alpha=2, beta=0)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    time.sleep(0.05)\n",
    "    frames += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(rejections)\n",
    "print(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
